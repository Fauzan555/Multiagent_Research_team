{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bee5ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langgraph langchain-google-genai langchain-community langchain-core python-dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ba50d5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da192b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyA2N-_t_H5fGOpsvTPZrdMM303ejSsmarQ\"\n",
    "\n",
    "import os\n",
    "from typing import Annotated, List, Tuple, Union\n",
    "from typing_extensions import TypedDict\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import functools\n",
    "\n",
    "import getpass\n",
    "GOOGLE_API_KEY = getpass.getpass(\"AIzaSyA2N-_t_H5fGOpsvTPZrdMM303ejSsmarQ \")\n",
    "os.environ[\"AIzaSyA2N-_t_H5fGOpsvTPZrdMM303ejSsmarQ\"] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61e76846",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"State shared between all agents in the graph\"\"\"\n",
    "    messages: Annotated[list, operator.add]\n",
    "    next: str\n",
    "    current_agent: str\n",
    "    research_topic: str\n",
    "    findings: dict\n",
    "    final_report: str\n",
    "\n",
    "\n",
    "class AgentResponse(TypedDict):\n",
    "    \"\"\"Standard response format for all agents\"\"\"\n",
    "    content: str\n",
    "    next_agent: str\n",
    "    findings: dict\n",
    "\n",
    "\n",
    "def create_llm(temperature: float = 0.1, model: str = \"gemini-1.5-flash\") -> ChatGoogleGenerativeAI:\n",
    "    \"\"\"Create a configured Gemini LLM instance\"\"\"\n",
    "    return ChatGoogleGenerativeAI(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        google_api_key=os.environ[\"GOOGLE_API_KEY\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8502b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_research_agent(llm: ChatGoogleGenerativeAI) -> callable:\n",
    "    \"\"\"Creates a research specialist agent for initial data gathering\"\"\"\n",
    "   \n",
    "    research_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a Research Specialist AI. Your role is to:\n",
    "        1. Analyze the research topic thoroughly\n",
    "        2. Identify key areas that need investigation\n",
    "        3. Provide initial research findings and insights\n",
    "        4. Suggest specific angles for deeper analysis\n",
    "       \n",
    "        Focus on providing comprehensive, accurate information and clear research directions.\n",
    "        Always structure your response with clear sections and bullet points.\n",
    "        \"\"\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"human\", \"Research Topic: {research_topic}\")\n",
    "    ])\n",
    "   \n",
    "    research_chain = research_prompt | llm\n",
    "   \n",
    "    def research_agent(state: AgentState) -> AgentState:\n",
    "        \"\"\"Execute research analysis\"\"\"\n",
    "        try:\n",
    "            response = research_chain.invoke({\n",
    "                \"messages\": state[\"messages\"],\n",
    "                \"research_topic\": state[\"research_topic\"]\n",
    "            })\n",
    "           \n",
    "            findings = {\n",
    "                \"research_overview\": response.content,\n",
    "                \"key_areas\": [\"area1\", \"area2\", \"area3\"],\n",
    "                \"initial_insights\": response.content[:500] + \"...\"\n",
    "            }\n",
    "           \n",
    "            return {\n",
    "                \"messages\": state[\"messages\"] + [AIMessage(content=response.content)],\n",
    "                \"next\": \"analyst\",\n",
    "                \"current_agent\": \"researcher\",\n",
    "                \"research_topic\": state[\"research_topic\"],\n",
    "                \"findings\": {**state.get(\"findings\", {}), \"research\": findings},\n",
    "                \"final_report\": state.get(\"final_report\", \"\")\n",
    "            }\n",
    "           \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Research agent error: {str(e)}\"\n",
    "            return {\n",
    "                \"messages\": state[\"messages\"] + [AIMessage(content=error_msg)],\n",
    "                \"next\": \"analyst\",\n",
    "                \"current_agent\": \"researcher\",\n",
    "                \"research_topic\": state[\"research_topic\"],\n",
    "                \"findings\": state.get(\"findings\", {}),\n",
    "                \"final_report\": state.get(\"final_report\", \"\")\n",
    "            }\n",
    "   \n",
    "    return research_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2adb45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analyst_agent(llm: ChatGoogleGenerativeAI) -> callable:\n",
    "    \"\"\"Creates a data analyst agent for deep analysis\"\"\"\n",
    "   \n",
    "    analyst_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a Data Analyst AI. Your role is to:\n",
    "        1. Analyze data and information provided by the research team\n",
    "        2. Identify patterns, trends, and correlations\n",
    "        3. Provide statistical insights and data-driven conclusions\n",
    "        4. Suggest actionable recommendations based on analysis\n",
    "       \n",
    "        Focus on quantitative analysis, data interpretation, and evidence-based insights.\n",
    "        Use clear metrics and concrete examples in your analysis.\n",
    "        \"\"\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"human\", \"Analyze the research findings for: {research_topic}\")\n",
    "    ])\n",
    "   \n",
    "    analyst_chain = analyst_prompt | llm\n",
    "   \n",
    "    def analyst_agent(state: AgentState) -> AgentState:\n",
    "        \"\"\"Execute data analysis\"\"\"\n",
    "        try:\n",
    "            response = analyst_chain.invoke({\n",
    "                \"messages\": state[\"messages\"],\n",
    "                \"research_topic\": state[\"research_topic\"]\n",
    "            })\n",
    "           \n",
    "            analysis_findings = {\n",
    "                \"analysis_summary\": response.content,\n",
    "                \"key_metrics\": [\"metric1\", \"metric2\", \"metric3\"],\n",
    "                \"recommendations\": response.content.split(\"recommendations:\")[-1] if \"recommendations:\" in response.content.lower() else \"No specific recommendations found\"\n",
    "            }\n",
    "           \n",
    "            return {\n",
    "                \"messages\": state[\"messages\"] + [AIMessage(content=response.content)],\n",
    "                \"next\": \"writer\",\n",
    "                \"current_agent\": \"analyst\",\n",
    "                \"research_topic\": state[\"research_topic\"],\n",
    "                \"findings\": {**state.get(\"findings\", {}), \"analysis\": analysis_findings},\n",
    "                \"final_report\": state.get(\"final_report\", \"\")\n",
    "            }\n",
    "           \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Analyst agent error: {str(e)}\"\n",
    "            return {\n",
    "                \"messages\": state[\"messages\"] + [AIMessage(content=error_msg)],\n",
    "                \"next\": \"writer\",\n",
    "                \"current_agent\": \"analyst\",\n",
    "                \"research_topic\": state[\"research_topic\"],\n",
    "                \"findings\": state.get(\"findings\", {}),\n",
    "                \"final_report\": state.get(\"final_report\", \"\")\n",
    "            }\n",
    "   \n",
    "    return analyst_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ed34ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_writer_agent(llm: ChatGoogleGenerativeAI) -> callable:\n",
    "    \"\"\"Creates a report writer agent for final documentation\"\"\"\n",
    "   \n",
    "    writer_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a Report Writer AI. Your role is to:\n",
    "        1. Synthesize all research and analysis into a comprehensive report\n",
    "        2. Create clear, professional documentation\n",
    "        3. Ensure proper structure with executive summary, findings, and conclusions\n",
    "        4. Make complex information accessible to various audiences\n",
    "       \n",
    "        Focus on clarity, completeness, and professional presentation.\n",
    "        Include specific examples and actionable insights.\n",
    "        \"\"\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"human\", \"Create a comprehensive report for: {research_topic}\")\n",
    "    ])\n",
    "   \n",
    "    writer_chain = writer_prompt | llm\n",
    "   \n",
    "    def writer_agent(state: AgentState) -> AgentState:\n",
    "        \"\"\"Execute report writing\"\"\"\n",
    "        try:\n",
    "            response = writer_chain.invoke({\n",
    "                \"messages\": state[\"messages\"],\n",
    "                \"research_topic\": state[\"research_topic\"]\n",
    "            })\n",
    "           \n",
    "            return {\n",
    "                \"messages\": state[\"messages\"] + [AIMessage(content=response.content)],\n",
    "                \"next\": \"supervisor\",\n",
    "                \"current_agent\": \"writer\",\n",
    "                \"research_topic\": state[\"research_topic\"],\n",
    "                \"findings\": state.get(\"findings\", {}),\n",
    "                \"final_report\": response.content\n",
    "            }\n",
    "           \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Writer agent error: {str(e)}\"\n",
    "            return {\n",
    "                \"messages\": state[\"messages\"] + [AIMessage(content=error_msg)],\n",
    "                \"next\": \"supervisor\",\n",
    "                \"current_agent\": \"writer\",\n",
    "                \"research_topic\": state[\"research_topic\"],\n",
    "                \"findings\": state.get(\"findings\", {}),\n",
    "                \"final_report\": f\"Error generating report: {str(e)}\"\n",
    "            }\n",
    "   \n",
    "    return writer_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f7f74a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_supervisor_agent(llm: ChatGoogleGenerativeAI, members: List[str]) -> callable:\n",
    "    \"\"\"Creates a supervisor agent to coordinate the team\"\"\"\n",
    "   \n",
    "    options = [\"FINISH\"] + members\n",
    "   \n",
    "    supervisor_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"\"\"You are a Supervisor AI managing a research team. Your team members are:\n",
    "        {', '.join(members)}\n",
    "       \n",
    "        Your responsibilities:\n",
    "        1. Coordinate the workflow between team members\n",
    "        2. Ensure each agent completes their specialized tasks\n",
    "        3. Determine when the research is complete\n",
    "        4. Maintain quality standards throughout the process\n",
    "       \n",
    "        Given the conversation, determine the next step:\n",
    "        - If research is needed: route to \"researcher\"\n",
    "        - If analysis is needed: route to \"analyst\"  \n",
    "        - If report writing is needed: route to \"writer\"\n",
    "        - If work is complete: route to \"FINISH\"\n",
    "       \n",
    "        Available options: {options}\n",
    "       \n",
    "        Respond with just the name of the next agent or \"FINISH\".\n",
    "        \"\"\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"human\", \"Current status: {current_agent} just completed their task for topic: {research_topic}\")\n",
    "    ])\n",
    "   \n",
    "    supervisor_chain = supervisor_prompt | llm\n",
    "   \n",
    "    def supervisor_agent(state: AgentState) -> AgentState:\n",
    "        \"\"\"Execute supervisor coordination\"\"\"\n",
    "        try:\n",
    "            response = supervisor_chain.invoke({\n",
    "                \"messages\": state[\"messages\"],\n",
    "                \"current_agent\": state.get(\"current_agent\", \"none\"),\n",
    "                \"research_topic\": state[\"research_topic\"]\n",
    "            })\n",
    "           \n",
    "            next_agent = response.content.strip().lower()\n",
    "           \n",
    "            if \"finish\" in next_agent or \"complete\" in next_agent:\n",
    "                next_step = \"FINISH\"\n",
    "            elif \"research\" in next_agent:\n",
    "                next_step = \"researcher\"\n",
    "            elif \"analy\" in next_agent:\n",
    "                next_step = \"analyst\"\n",
    "            elif \"writ\" in next_agent:\n",
    "                next_step = \"writer\"\n",
    "            else:\n",
    "                current = state.get(\"current_agent\", \"\")\n",
    "                if current == \"researcher\":\n",
    "                    next_step = \"analyst\"\n",
    "                elif current == \"analyst\":\n",
    "                    next_step = \"writer\"\n",
    "                elif current == \"writer\":\n",
    "                    next_step = \"FINISH\"\n",
    "                else:\n",
    "                    next_step = \"researcher\"\n",
    "           \n",
    "            return {\n",
    "                \"messages\": state[\"messages\"] + [AIMessage(content=f\"Supervisor decision: Next agent is {next_step}\")],\n",
    "                \"next\": next_step,\n",
    "                \"current_agent\": \"supervisor\",\n",
    "                \"research_topic\": state[\"research_topic\"],\n",
    "                \"findings\": state.get(\"findings\", {}),\n",
    "                \"final_report\": state.get(\"final_report\", \"\")\n",
    "            }\n",
    "           \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Supervisor error: {str(e)}\"\n",
    "            return {\n",
    "                \"messages\": state[\"messages\"] + [AIMessage(content=error_msg)],\n",
    "                \"next\": \"FINISH\",\n",
    "                \"current_agent\": \"supervisor\",\n",
    "                \"research_topic\": state[\"research_topic\"],\n",
    "                \"findings\": state.get(\"findings\", {}),\n",
    "                \"final_report\": state.get(\"final_report\", \"\")\n",
    "            }\n",
    "   \n",
    "    return supervisor_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f2032c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_research_team_graph() -> StateGraph:\n",
    "    \"\"\"Creates the complete research team workflow graph\"\"\"\n",
    "   \n",
    "    llm = create_llm()\n",
    "   \n",
    "    members = [\"researcher\", \"analyst\", \"writer\"]\n",
    "    researcher = create_research_agent(llm)\n",
    "    analyst = create_analyst_agent(llm)\n",
    "    writer = create_writer_agent(llm)\n",
    "    supervisor = create_supervisor_agent(llm, members)\n",
    "   \n",
    "    workflow = StateGraph(AgentState)\n",
    "   \n",
    "    workflow.add_node(\"researcher\", researcher)\n",
    "    workflow.add_node(\"analyst\", analyst)\n",
    "    workflow.add_node(\"writer\", writer)\n",
    "    workflow.add_node(\"supervisor\", supervisor)\n",
    "   \n",
    "    workflow.add_edge(\"researcher\", \"supervisor\")\n",
    "    workflow.add_edge(\"analyst\", \"supervisor\")\n",
    "    workflow.add_edge(\"writer\", \"supervisor\")\n",
    "   \n",
    "    workflow.add_conditional_edges(\n",
    "        \"supervisor\",\n",
    "        lambda x: x[\"next\"],\n",
    "        {\n",
    "            \"researcher\": \"researcher\",\n",
    "            \"analyst\": \"analyst\",\n",
    "            \"writer\": \"writer\",\n",
    "            \"FINISH\": END\n",
    "        }\n",
    "    )\n",
    "   \n",
    "    workflow.set_entry_point(\"supervisor\")\n",
    "   \n",
    "    return workflow\n",
    "\n",
    "\n",
    "def compile_research_team():\n",
    "    \"\"\"Compile the research team graph with memory\"\"\"\n",
    "    workflow = create_research_team_graph()\n",
    "   \n",
    "    memory = MemorySaver()\n",
    "   \n",
    "    app = workflow.compile(checkpointer=memory)\n",
    "   \n",
    "    return app\n",
    "\n",
    "\n",
    "def run_research_team(topic: str, thread_id: str = \"research_session_1\"):\n",
    "    \"\"\"Run the complete research team workflow\"\"\"\n",
    "   \n",
    "    app = compile_research_team()\n",
    "   \n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=f\"Research the topic: {topic}\")],\n",
    "        \"research_topic\": topic,\n",
    "        \"next\": \"researcher\",\n",
    "        \"current_agent\": \"start\",\n",
    "        \"findings\": {},\n",
    "        \"final_report\": \"\"\n",
    "    }\n",
    "   \n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "   \n",
    "    print(f\" Starting research on: {topic}\")\n",
    "    print(\"=\" * 50)\n",
    "   \n",
    "    try:\n",
    "        final_state = None\n",
    "        for step, state in enumerate(app.stream(initial_state, config=config)):\n",
    "            print(f\"\\n Step {step + 1}: {list(state.keys())[0]}\")\n",
    "           \n",
    "            current_state = list(state.values())[0]\n",
    "            if current_state[\"messages\"]:\n",
    "                last_message = current_state[\"messages\"][-1]\n",
    "                if isinstance(last_message, AIMessage):\n",
    "                    print(f\" {last_message.content[:200]}...\")\n",
    "           \n",
    "            final_state = current_state\n",
    "           \n",
    "            if step > 10:\n",
    "                print(\"  Maximum steps reached. Stopping execution.\")\n",
    "                break\n",
    "       \n",
    "        return final_state\n",
    "       \n",
    "    except Exception as e:\n",
    "        print(f\" Error during execution: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b782fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting research on: Artificial Intelligence in Education\n",
      "==================================================\n",
      "\n",
      " Step 1: supervisor\n",
      " Supervisor decision: Next agent is researcher...\n",
      "\n",
      " Step 2: researcher\n",
      " ## Research Topic: Artificial Intelligence in Education\n",
      "\n",
      "This research explores the multifaceted impact of Artificial Intelligence (AI) on education, encompassing its applications, benefits, challenge...\n",
      "\n",
      " Step 3: supervisor\n",
      " Supervisor decision: Next agent is analyst...\n",
      "\n",
      " Step 4: analyst\n",
      " Analyzing research findings on Artificial Intelligence (AI) in education reveals a complex picture with both promising potential and significant challenges.  While the field is rapidly evolving, sever...\n",
      "\n",
      " Step 5: supervisor\n",
      " Supervisor decision: Next agent is writer...\n",
      "\n",
      " Step 6: writer\n",
      " ## Artificial Intelligence in Education: A Comprehensive Report\n",
      "\n",
      "**Executive Summary:**\n",
      "\n",
      "Artificial intelligence (AI) is rapidly transforming various sectors, and education is no exception.  This repo...\n",
      "\n",
      " Step 7: supervisor\n",
      " Supervisor decision: Next agent is FINISH...\n",
      "\n",
      "==================================================\n",
      " FINAL RESULTS\n",
      "==================================================\n",
      " Final Agent: supervisor\n",
      " Findings: 2 sections\n",
      " Report Length: 6653 characters\n",
      "\n",
      " FINAL REPORT:\n",
      "------------------------------\n",
      "## Artificial Intelligence in Education: A Comprehensive Report\n",
      "\n",
      "**Executive Summary:**\n",
      "\n",
      "Artificial intelligence (AI) is rapidly transforming various sectors, and education is no exception.  This report examines the burgeoning role of AI in education, exploring its applications, benefits, challenges, and future implications.  While AI offers significant potential for personalized learning, increased accessibility, and enhanced efficiency, its implementation requires careful consideration of ethical concerns, data privacy, and the crucial role of human educators.  This report highlights the need for robust research, effective teacher training, and equitable access to ensure AI's positive impact on learning outcomes and educational equity.\n",
      "\n",
      "\n",
      "**I. Introduction:**\n",
      "\n",
      "The integration of AI in education is poised to revolutionize the learning experience.  AI-powered tools offer the potential to personalize learning pathways, automate administrative tasks, and create more engaging and accessible educational resources.  However, the successful implementation of AI in education requires a nuanced understanding of its capabilities and limitations, along with a commitment to addressing ethical and practical challenges.\n",
      "\n",
      "\n",
      "**II. Applications of AI in Education:**\n",
      "\n",
      "AI is being applied in diverse ways within the educational landscape:\n",
      "\n",
      "* **Personalized Learning:** Adaptive learning platforms utilize AI algorithms to analyze student performance and tailor learning materials and pace to individual needs.  Intelligent tutoring systems (ITS) provide personalized feedback and guidance, adapting to student strengths and weaknesses.  AI-powered assessment tools offer more nuanced and comprehensive evaluations of student understanding.\n",
      "\n",
      "* **Automated Administrative Tasks:** AI can automate time-consuming administrative tasks such as grading, scheduling, and record-keeping, freeing up educators' time for more direct student interaction and curriculum development.\n",
      "\n",
      "* **Intelligent Content Creation:** AI tools can assist in generating educational materials, including lesson plans, quizzes, and interactive simulations.  This can help educators create more engaging and diverse learning resources, but careful review and quality control are essential.\n",
      "\n",
      "* **Accessibility and Inclusivity:** AI-powered assistive technologies, such as text-to-speech software, translation services, and real-time captioning, can significantly improve access to education for students with disabilities and those from diverse linguistic backgrounds.\n",
      "\n",
      "* **Early Childhood Education:** AI is increasingly being explored in early childhood settings, with applications ranging from interactive learning games to tools that monitor child development and provide early intervention support.  However, ethical considerations related to data privacy and child development are paramount.\n",
      "\n",
      "\n",
      "**III. Benefits of AI in Education:**\n",
      "\n",
      "The potential benefits of AI in education are substantial:\n",
      "\n",
      "* **Improved Learning Outcomes:**  Personalized learning experiences can lead to improved student achievement, engagement, and motivation.  AI-powered tools can provide targeted support and feedback, addressing individual learning needs more effectively.\n",
      "\n",
      "* **Enhanced Accessibility:** AI can break down barriers to education for students with disabilities and those in underserved communities, promoting inclusivity and equity.\n",
      "\n",
      "* **Increased Efficiency:** Automating administrative tasks frees up educators' time, allowing them to focus on teaching and student support.\n",
      "\n",
      "* **Data-Driven Insights:** AI can provide valuable insights into student learning patterns, enabling educators to make data-driven decisions about instruction and curriculum development.\n",
      "\n",
      "\n",
      "**IV. Challenges and Concerns:**\n",
      "\n",
      "Despite its potential, the integration of AI in education presents several challenges:\n",
      "\n",
      "* **Algorithmic Bias:** AI algorithms are trained on data, and if that data reflects existing societal biases, the algorithms can perpetuate and even amplify those biases, leading to unfair or discriminatory outcomes for certain student groups.\n",
      "\n",
      "* **Data Privacy and Security:**  The collection and use of student data raise significant concerns about privacy and security.  Robust data protection measures and ethical guidelines are essential.\n",
      "\n",
      "* **Equity and Access:**  Unequal access to technology and digital literacy skills can exacerbate existing inequalities in education.  Ensuring equitable access to AI-powered tools is crucial.\n",
      "\n",
      "* **Lack of Teacher Training:**  Effective integration of AI requires adequate teacher training and professional development to equip educators with the skills and knowledge to use these tools effectively.\n",
      "\n",
      "* **Over-reliance on Technology:**  A balanced approach is needed to avoid over-reliance on technology and maintain the crucial role of human interaction and social-emotional learning.\n",
      "\n",
      "\n",
      "**V. Ethical Considerations:**\n",
      "\n",
      "The ethical implications of using AI in education must be carefully considered:\n",
      "\n",
      "* **Transparency and Explainability:**  AI algorithms should be transparent and explainable, allowing educators and students to understand how decisions are made.\n",
      "\n",
      "* **Accountability:**  Clear lines of accountability are needed to address potential biases and errors in AI systems.\n",
      "\n",
      "* **Human Oversight:**  Human oversight is essential to ensure that AI tools are used responsibly and ethically.\n",
      "\n",
      "\n",
      "**VI. Future Directions:**\n",
      "\n",
      "Future research and development in AI in education should focus on:\n",
      "\n",
      "* **Rigorous Evaluation:**  Conducting large-scale, rigorous studies to evaluate the effectiveness of AI-powered educational tools.\n",
      "\n",
      "* **Ethical Frameworks:**  Developing clear ethical guidelines and regulatory frameworks for the use of AI in education.\n",
      "\n",
      "* **Human-Centered Design:**  Designing AI tools that prioritize human needs and values, supporting rather than replacing human teachers.\n",
      "\n",
      "* **Teacher Professional Development:**  Investing in comprehensive teacher training programs.\n",
      "\n",
      "* **Interdisciplinary Collaboration:**  Fostering collaboration between educators, AI researchers, policymakers, and other stakeholders.\n",
      "\n",
      "\n",
      "**VII. Conclusion:**\n",
      "\n",
      "AI has the potential to significantly improve education, but its successful implementation requires careful planning, ethical considerations, and a commitment to equity and accessibility.  By addressing the challenges and embracing the opportunities, AI can play a transformative role in creating more personalized, engaging, and effective learning experiences for all students.  Ongoing research, collaboration, and a human-centered approach are crucial for realizing the full potential of AI in education.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    result = run_research_team(\"Artificial Intelligence in Education\")\n",
    "   \n",
    "    if result:\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\" FINAL RESULTS\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\" Final Agent: {result['current_agent']}\")\n",
    "        print(f\" Findings: {len(result['findings'])} sections\")\n",
    "        print(f\" Report Length: {len(result['final_report'])} characters\")\n",
    "       \n",
    "        if result['final_report']:\n",
    "            print(\"\\n FINAL REPORT:\")\n",
    "            print(\"-\" * 30)\n",
    "            print(result['final_report'])\n",
    "\n",
    "\n",
    "def interactive_research_session():\n",
    "    \"\"\"Run an interactive research session\"\"\"\n",
    "   \n",
    "    app = compile_research_team()\n",
    "   \n",
    "    print(\" Interactive Research Team Session\")\n",
    "    print(\"Enter 'quit' to exit\\n\")\n",
    "   \n",
    "    session_count = 0\n",
    "   \n",
    "    while True:\n",
    "        topic = input(\" Enter research topic: \").strip()\n",
    "       \n",
    "        if topic.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\" Goodbye!\")\n",
    "            break\n",
    "       \n",
    "        if not topic:\n",
    "            print(\" Please enter a valid topic.\")\n",
    "            continue\n",
    "       \n",
    "        session_count += 1\n",
    "        thread_id = f\"interactive_session_{session_count}\"\n",
    "       \n",
    "        result = run_research_team(topic, thread_id)\n",
    "       \n",
    "        if result and result['final_report']:\n",
    "            print(f\"\\n Research completed for: {topic}\")\n",
    "            print(f\" Report preview: {result['final_report'][:300]}...\")\n",
    "           \n",
    "            show_full = input(\"\\n Show full report? (y/n): \").lower()\n",
    "            if show_full.startswith('y'):\n",
    "                print(\"\\n\" + \"=\" * 60)\n",
    "                print(\" COMPLETE RESEARCH REPORT\")\n",
    "                print(\"=\" * 60)\n",
    "                print(result['final_report'])\n",
    "       \n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_custom_agent(role: str, instructions: str, llm: ChatGoogleGenerativeAI) -> callable:\n",
    "    \"\"\"Create a custom agent with specific role and instructions\"\"\"\n",
    "   \n",
    "    custom_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"\"\"You are a {role} AI.\n",
    "       \n",
    "        Your specific instructions:\n",
    "        {instructions}\n",
    "       \n",
    "        Always provide detailed, professional responses relevant to your role.\n",
    "        \"\"\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"human\", \"Task: {task}\")\n",
    "    ])\n",
    "   \n",
    "    custom_chain = custom_prompt | llm\n",
    "   \n",
    "    def custom_agent(state: AgentState) -> AgentState:\n",
    "        \"\"\"Execute custom agent task\"\"\"\n",
    "        try:\n",
    "            response = custom_chain.invoke({\n",
    "                \"messages\": state[\"messages\"],\n",
    "                \"task\": state[\"research_topic\"]\n",
    "            })\n",
    "           \n",
    "            return {\n",
    "                \"messages\": state[\"messages\"] + [AIMessage(content=response.content)],\n",
    "                \"next\": \"supervisor\",\n",
    "                \"current_agent\": role.lower().replace(\" \", \"_\"),\n",
    "                \"research_topic\": state[\"research_topic\"],\n",
    "                \"findings\": state.get(\"findings\", {}),\n",
    "                \"final_report\": state.get(\"final_report\", \"\")\n",
    "            }\n",
    "           \n",
    "        except Exception as e:\n",
    "            error_msg = f\"{role} agent error: {str(e)}\"\n",
    "            return {\n",
    "                \"messages\": state[\"messages\"] + [AIMessage(content=error_msg)],\n",
    "                \"next\": \"supervisor\",\n",
    "                \"current_agent\": role.lower().replace(\" \", \"_\"),\n",
    "                \"research_topic\": state[\"research_topic\"],\n",
    "                \"findings\": state.get(\"findings\", {}),\n",
    "                \"final_report\": state.get(\"final_report\", \"\")\n",
    "            }\n",
    "   \n",
    "    return custom_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "149db3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LangGraph Research Team - Quick Start Demo\n",
      "==================================================\n",
      "\n",
      " Demo 1: Climate Change Impact on Human health\n",
      "----------------------------------------\n",
      " Starting research on: Climate Change Impact on Human health\n",
      "==================================================\n",
      "\n",
      " Step 1: supervisor\n",
      " Supervisor decision: Next agent is researcher...\n",
      "\n",
      " Step 2: researcher\n",
      " ## Research Topic: Climate Change Impact on Human Health\n",
      "\n",
      "This research topic encompasses a vast and complex area.  To effectively investigate it, we need to break it down into manageable sections.  B...\n",
      "\n",
      " Step 3: supervisor\n",
      " Supervisor decision: Next agent is analyst...\n",
      "\n",
      " Step 4: analyst\n",
      " Analyzing research findings on the impact of climate change on human health reveals a complex and multifaceted problem with far-reaching consequences.  The available evidence overwhelmingly supports a...\n",
      "\n",
      " Step 5: supervisor\n",
      " Supervisor decision: Next agent is writer...\n",
      "\n",
      " Step 6: writer\n",
      " ## The Impact of Climate Change on Human Health: A Comprehensive Report\n",
      "\n",
      "**Executive Summary:**\n",
      "\n",
      "Climate change poses a significant and escalating threat to human health globally.  This report synthes...\n",
      "\n",
      " Step 7: supervisor\n",
      " Supervisor decision: Next agent is FINISH...\n",
      " Research completed successfully!\n",
      " Report preview: ## The Impact of Climate Change on Human Health: A Comprehensive Report\n",
      "\n",
      "**Executive Summary:**\n",
      "\n",
      "Climate change poses a significant and escalating thr...\n",
      "\n",
      "==============================\n",
      "\n",
      " Demo 2: Quantum Computing Applications in Software Development\n",
      "----------------------------------------\n",
      " Starting research on: Quantum Computing Applications in Software Development\n",
      "==================================================\n",
      "\n",
      " Step 1: supervisor\n",
      " Supervisor decision: Next agent is researcher...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 42\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Step 2: researcher\n",
      " Research agent error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 38\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Step 3: supervisor\n",
      " Supervisor decision: Next agent is analyst...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 34\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Step 4: analyst\n",
      " Analyst agent error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [v...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 31\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Step 5: supervisor\n",
      " Supervisor error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [viol...\n",
      " Research failed\n",
      "\n",
      "==============================\n",
      "\n",
      " Demo 3: Digital Privacy in the Modern Digital payment system\n",
      "----------------------------------------\n",
      " Starting research on: Digital Privacy in the Modern Digital payment system\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Step 1: supervisor\n",
      " Supervisor error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [viol...\n",
      " Research failed\n",
      "\n",
      "==============================\n",
      " Demo completed!\n"
     ]
    }
   ],
   "source": [
    "def visualize_graph():\n",
    "    \"\"\"Visualize the research team graph structure\"\"\"\n",
    "   \n",
    "    try:\n",
    "        app = compile_research_team()\n",
    "       \n",
    "        graph_repr = app.get_graph()\n",
    "       \n",
    "        print(\"  Research Team Graph Structure\")\n",
    "        print(\"=\" * 40)\n",
    "        print(f\"Nodes: {list(graph_repr.nodes.keys())}\")\n",
    "        print(f\"Edges: {[(edge.source, edge.target) for edge in graph_repr.edges]}\")\n",
    "       \n",
    "        try:\n",
    "            graph_repr.draw_mermaid()\n",
    "        except:\n",
    "            print(\" Visual graph requires mermaid-py package\")\n",
    "            print(\"Install with: !pip install mermaid-py\")\n",
    "           \n",
    "    except Exception as e:\n",
    "        print(f\" Error visualizing graph: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def monitor_research_performance(topic: str):\n",
    "    \"\"\"Monitor and report performance metrics\"\"\"\n",
    "   \n",
    "    start_time = time.time()\n",
    "    print(f\"  Starting performance monitoring for: {topic}\")\n",
    "   \n",
    "    result = run_research_team(topic, f\"perf_test_{int(time.time())}\")\n",
    "   \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "   \n",
    "    metrics = {\n",
    "        \"duration\": duration,\n",
    "        \"total_messages\": len(result[\"messages\"]) if result else 0,\n",
    "        \"findings_sections\": len(result[\"findings\"]) if result else 0,\n",
    "        \"report_length\": len(result[\"final_report\"]) if result and result[\"final_report\"] else 0,\n",
    "        \"success\": result is not None\n",
    "    }\n",
    "   \n",
    "    print(\"\\n PERFORMANCE METRICS\")\n",
    "    print(\"=\" * 30)\n",
    "    print(f\"  Duration: {duration:.2f} seconds\")\n",
    "    print(f\" Total Messages: {metrics['total_messages']}\")\n",
    "    print(f\" Findings Sections: {metrics['findings_sections']}\")\n",
    "    print(f\" Report Length: {metrics['report_length']} chars\")\n",
    "    print(f\" Success: {metrics['success']}\")\n",
    "   \n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def quick_start_demo():\n",
    "    \"\"\"Complete demo of the research team system\"\"\"\n",
    "   \n",
    "    print(\" LangGraph Research Team - Quick Start Demo\")\n",
    "    print(\"=\" * 50)\n",
    "   \n",
    "    topics = [\n",
    "        \"Climate Change Impact on Human health\",\n",
    "        \"Quantum Computing Applications in Software Development\",\n",
    "        \"Digital Privacy in the Modern Digital payment system\"\n",
    "    ]\n",
    "   \n",
    "    for i, topic in enumerate(topics, 1):\n",
    "        print(f\"\\n Demo {i}: {topic}\")\n",
    "        print(\"-\" * 40)\n",
    "       \n",
    "        try:\n",
    "            result = run_research_team(topic, f\"demo_{i}\")\n",
    "           \n",
    "            if result and result['final_report']:\n",
    "                print(f\" Research completed successfully!\")\n",
    "                print(f\" Report preview: {result['final_report'][:150]}...\")\n",
    "            else:\n",
    "                print(\" Research failed\")\n",
    "               \n",
    "        except Exception as e:\n",
    "            print(f\" Error in demo {i}: {str(e)}\")\n",
    "       \n",
    "        print(\"\\n\" + \"=\"*30)\n",
    "   \n",
    "    print(\" Demo completed!\")\n",
    "\n",
    "\n",
    "quick_start_demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
